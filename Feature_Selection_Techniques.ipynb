{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2842b98b-cac6-4b98-af15-64f480e8d0e4",
   "metadata": {},
   "source": [
    "\n",
    "# Feature Selection Techniques â€” Full Guide (Theory + Code)\n",
    "\n",
    "**Feature selection** is the process of selecting the most relevant features (columns) for use in model training. It helps:\n",
    "\n",
    "* Improve model performance\n",
    "* Reduce overfitting\n",
    "* Reduce training time\n",
    "* Improve interpretability\n",
    "\n",
    "---\n",
    "\n",
    "##### 1. **Correlation-Based Feature Selection**\n",
    "\n",
    "##### What is it?\n",
    "\n",
    "* Correlation measures the linear relationship between two features.\n",
    "* Highly correlated features (multicollinearity) can confuse models, especially linear models.\n",
    "* You can remove one of the two highly correlated features.\n",
    "\n",
    "\n",
    "\n",
    "##### When to use:\n",
    "\n",
    "* When you suspect **multicollinearity** (especially in linear regression).\n",
    "* When you want to reduce feature redundancy.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac0b940-76b5-4486-94f3-3ff4d37767e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Calculate correlation matrix\n",
    "corr_matrix = df.corr(numeric_only=True)\n",
    "\n",
    "# 2. Visualize correlation matrix\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "\n",
    "# 3. Drop features with high correlation (> 0.9)\n",
    "def remove_highly_correlated(df, threshold=0.9):\n",
    "    corr_matrix = df.corr().abs()\n",
    "    upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > threshold)]\n",
    "    return df.drop(columns=to_drop)\n",
    "\n",
    "df_filtered = remove_highly_correlated(df, threshold=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618c1fa0-2f12-428b-9aeb-ae91c3ef9f5a",
   "metadata": {},
   "source": [
    "##### 2. **Variance Threshold (Low Variance Filter)**\n",
    "\n",
    "##### What is it?\n",
    "\n",
    "* If a feature has **low variance**, it doesn't change much â†’ provides little information â†’ can be removed.\n",
    "* Especially useful in high-dimensional data (e.g., text or image features).\n",
    "\n",
    "##### When to use:\n",
    "\n",
    "* When many features are **binary** or **categorical** encoded.\n",
    "* When preprocessing **text or image data**.\n",
    "* To remove uninformative columns before modeling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccadbfe1-e630-4b80-b261-3e5c3ff14083",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Remove features with variance below 0.01\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "df_reduced = selector.fit_transform(df)\n",
    "\n",
    "# Get selected column names\n",
    "selected_columns = df.columns[selector.get_support()]\n",
    "df_reduced = pd.DataFrame(df_reduced, columns=selected_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0111ace1-16a8-4875-b653-7ebcdd3e66de",
   "metadata": {},
   "source": [
    "##### 3. **SelectKBest (Univariate Feature Selection)**\n",
    "\n",
    "##### What is it?\n",
    "\n",
    "* Selects the top **k** features that have the strongest relationship with the target.\n",
    "* Based on statistical tests:\n",
    "\n",
    "  * `f_classif` for classification\n",
    "  * `f_regression` for regression\n",
    "  * `chi2` for categorical data\n",
    "\n",
    "\n",
    "#####  When to use:\n",
    "\n",
    "* You want to select **top K features** before modeling.\n",
    "* Especially useful for quick filtering before model selection.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9ba931-efef-4903-a9c3-a36a3aea58c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Select top 5 features using ANOVA F-test\n",
    "selector = SelectKBest(score_func=f_classif, k=5)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "# Get selected features\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "print(\"Selected features:\", selected_features.tolist())\n",
    "\n",
    "# Rebuild new DataFrame\n",
    "X_selected = pd.DataFrame(X_new, columns=selected_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07023b0-7b6e-4d43-b9f5-d4331cfb525b",
   "metadata": {},
   "source": [
    "\n",
    "#####Other Feature Selection Techniques\n",
    "\n",
    "| Technique                               | Description                                                   |\n",
    "| --------------------------------------- | ------------------------------------------------------------- |\n",
    "| **Recursive Feature Elimination (RFE)** | Iteratively builds model and removes weakest features         |\n",
    "| **L1 Regularization (Lasso)**           | Penalizes irrelevant features â†’ zero weights                  |\n",
    "| **Tree-based Feature Importance**       | Uses models like Random Forest or XGBoost to rank features    |\n",
    "| **Mutual Information**                  | Measures non-linear relationships between features and target |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§  Summary Table\n",
    "\n",
    "| Technique          | Type     | When to Use                                   |\n",
    "| ------------------ | -------- | --------------------------------------------- |\n",
    "| Correlation        | Filter   | To remove multicollinearity                   |\n",
    "| Variance Threshold | Filter   | To remove features with no variance           |\n",
    "| SelectKBest        | Filter   | To select top-k features based on score       |\n",
    "| RFE                | Wrapper  | When using a model to recursively remove vars |\n",
    "| Lasso (L1)         | Embedded | When using linear models with regularization  |\n",
    "| Tree Importance    | Embedded | When using tree-based models                  |\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
